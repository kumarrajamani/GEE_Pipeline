{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61828bef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef6993a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set MFA and run the below command to download training data\n",
    "!aws s3 cp 's3://ai-eo-sandbox/Raja/training_data_LSTM/' 'training_data/' --recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0150a82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['S2_t0_B3', 'S2_t1_B3', 'S2_t2_B3', 'S2_t3_B3', 'S2_t4_B3', 'S2_t5_B3',\n",
       "       'S2_t6_B3', 'S2_t7_B3', 'S2_t8_B3', 'S2_t9_B3',\n",
       "       ...\n",
       "       'S2_t6_SAVI', 'S2_t7_SAVI', 'S2_t8_SAVI', 'S2_t9_SAVI', 'S2_t10_SAVI',\n",
       "       'S2_t11_SAVI', 'S2_t12_SAVI', 'Crop', 'Country', 'source'],\n",
       "      dtype='object', length=198)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#download from S3 path \n",
    "df = pd.read_csv('training_data/df_train.csv', index_col=False)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c443424e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crop\n",
       "Maize     1708212\n",
       "Wheat      234748\n",
       "Others      46119\n",
       "Potato      32851\n",
       "Rice        20604\n",
       "Bean        11138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d887deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b55ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = ['S2_t0_','S2_t1_','S2_t2_','S2_t3_','S2_t4_','S2_t5_','S2_t6_','S2_t7_','S2_t8_','S2_t9_','S2_t10_','S2_t11_','S2_t12_',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a17d868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = ['B3','B4','B5','B6','B7','B8','B11','B12','B8A','BSI','GCVI','LSWI','NDRE','NDVI','SAVI']\n",
    "li_bands = []\n",
    "for bnd in bands:\n",
    "    col_lis = [x + bnd for x in b]\n",
    "#     df[col_lis] = df[col_lis].apply(lambda row: row.interpolate(), axis=1)\n",
    "    li_bands.append(col_lis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d4b68183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S2_t0_B3',\n",
       " 'S2_t1_B3',\n",
       " 'S2_t2_B3',\n",
       " 'S2_t3_B3',\n",
       " 'S2_t4_B3',\n",
       " 'S2_t5_B3',\n",
       " 'S2_t6_B3',\n",
       " 'S2_t7_B3',\n",
       " 'S2_t8_B3',\n",
       " 'S2_t9_B3',\n",
       " 'S2_t10_B3',\n",
       " 'S2_t11_B3',\n",
       " 'S2_t12_B3',\n",
       " 'S2_t0_B4',\n",
       " 'S2_t1_B4',\n",
       " 'S2_t2_B4',\n",
       " 'S2_t3_B4',\n",
       " 'S2_t4_B4',\n",
       " 'S2_t5_B4',\n",
       " 'S2_t6_B4',\n",
       " 'S2_t7_B4',\n",
       " 'S2_t8_B4',\n",
       " 'S2_t9_B4',\n",
       " 'S2_t10_B4',\n",
       " 'S2_t11_B4',\n",
       " 'S2_t12_B4',\n",
       " 'S2_t0_B5',\n",
       " 'S2_t1_B5',\n",
       " 'S2_t2_B5',\n",
       " 'S2_t3_B5',\n",
       " 'S2_t4_B5',\n",
       " 'S2_t5_B5',\n",
       " 'S2_t6_B5',\n",
       " 'S2_t7_B5',\n",
       " 'S2_t8_B5',\n",
       " 'S2_t9_B5',\n",
       " 'S2_t10_B5',\n",
       " 'S2_t11_B5',\n",
       " 'S2_t12_B5',\n",
       " 'S2_t0_B6',\n",
       " 'S2_t1_B6',\n",
       " 'S2_t2_B6',\n",
       " 'S2_t3_B6',\n",
       " 'S2_t4_B6',\n",
       " 'S2_t5_B6',\n",
       " 'S2_t6_B6',\n",
       " 'S2_t7_B6',\n",
       " 'S2_t8_B6',\n",
       " 'S2_t9_B6',\n",
       " 'S2_t10_B6',\n",
       " 'S2_t11_B6',\n",
       " 'S2_t12_B6',\n",
       " 'S2_t0_B7',\n",
       " 'S2_t1_B7',\n",
       " 'S2_t2_B7',\n",
       " 'S2_t3_B7',\n",
       " 'S2_t4_B7',\n",
       " 'S2_t5_B7',\n",
       " 'S2_t6_B7',\n",
       " 'S2_t7_B7',\n",
       " 'S2_t8_B7',\n",
       " 'S2_t9_B7',\n",
       " 'S2_t10_B7',\n",
       " 'S2_t11_B7',\n",
       " 'S2_t12_B7',\n",
       " 'S2_t0_B8',\n",
       " 'S2_t1_B8',\n",
       " 'S2_t2_B8',\n",
       " 'S2_t3_B8',\n",
       " 'S2_t4_B8',\n",
       " 'S2_t5_B8',\n",
       " 'S2_t6_B8',\n",
       " 'S2_t7_B8',\n",
       " 'S2_t8_B8',\n",
       " 'S2_t9_B8',\n",
       " 'S2_t10_B8',\n",
       " 'S2_t11_B8',\n",
       " 'S2_t12_B8',\n",
       " 'S2_t0_B11',\n",
       " 'S2_t1_B11',\n",
       " 'S2_t2_B11',\n",
       " 'S2_t3_B11',\n",
       " 'S2_t4_B11',\n",
       " 'S2_t5_B11',\n",
       " 'S2_t6_B11',\n",
       " 'S2_t7_B11',\n",
       " 'S2_t8_B11',\n",
       " 'S2_t9_B11',\n",
       " 'S2_t10_B11',\n",
       " 'S2_t11_B11',\n",
       " 'S2_t12_B11',\n",
       " 'S2_t0_B12',\n",
       " 'S2_t1_B12',\n",
       " 'S2_t2_B12',\n",
       " 'S2_t3_B12',\n",
       " 'S2_t4_B12',\n",
       " 'S2_t5_B12',\n",
       " 'S2_t6_B12',\n",
       " 'S2_t7_B12',\n",
       " 'S2_t8_B12',\n",
       " 'S2_t9_B12',\n",
       " 'S2_t10_B12',\n",
       " 'S2_t11_B12',\n",
       " 'S2_t12_B12',\n",
       " 'S2_t0_B8A',\n",
       " 'S2_t1_B8A',\n",
       " 'S2_t2_B8A',\n",
       " 'S2_t3_B8A',\n",
       " 'S2_t4_B8A',\n",
       " 'S2_t5_B8A',\n",
       " 'S2_t6_B8A',\n",
       " 'S2_t7_B8A',\n",
       " 'S2_t8_B8A',\n",
       " 'S2_t9_B8A',\n",
       " 'S2_t10_B8A',\n",
       " 'S2_t11_B8A',\n",
       " 'S2_t12_B8A',\n",
       " 'S2_t0_BSI',\n",
       " 'S2_t1_BSI',\n",
       " 'S2_t2_BSI',\n",
       " 'S2_t3_BSI',\n",
       " 'S2_t4_BSI',\n",
       " 'S2_t5_BSI',\n",
       " 'S2_t6_BSI',\n",
       " 'S2_t7_BSI',\n",
       " 'S2_t8_BSI',\n",
       " 'S2_t9_BSI',\n",
       " 'S2_t10_BSI',\n",
       " 'S2_t11_BSI',\n",
       " 'S2_t12_BSI',\n",
       " 'S2_t0_GCVI',\n",
       " 'S2_t1_GCVI',\n",
       " 'S2_t2_GCVI',\n",
       " 'S2_t3_GCVI',\n",
       " 'S2_t4_GCVI',\n",
       " 'S2_t5_GCVI',\n",
       " 'S2_t6_GCVI',\n",
       " 'S2_t7_GCVI',\n",
       " 'S2_t8_GCVI',\n",
       " 'S2_t9_GCVI',\n",
       " 'S2_t10_GCVI',\n",
       " 'S2_t11_GCVI',\n",
       " 'S2_t12_GCVI',\n",
       " 'S2_t0_LSWI',\n",
       " 'S2_t1_LSWI',\n",
       " 'S2_t2_LSWI',\n",
       " 'S2_t3_LSWI',\n",
       " 'S2_t4_LSWI',\n",
       " 'S2_t5_LSWI',\n",
       " 'S2_t6_LSWI',\n",
       " 'S2_t7_LSWI',\n",
       " 'S2_t8_LSWI',\n",
       " 'S2_t9_LSWI',\n",
       " 'S2_t10_LSWI',\n",
       " 'S2_t11_LSWI',\n",
       " 'S2_t12_LSWI',\n",
       " 'S2_t0_NDRE',\n",
       " 'S2_t1_NDRE',\n",
       " 'S2_t2_NDRE',\n",
       " 'S2_t3_NDRE',\n",
       " 'S2_t4_NDRE',\n",
       " 'S2_t5_NDRE',\n",
       " 'S2_t6_NDRE',\n",
       " 'S2_t7_NDRE',\n",
       " 'S2_t8_NDRE',\n",
       " 'S2_t9_NDRE',\n",
       " 'S2_t10_NDRE',\n",
       " 'S2_t11_NDRE',\n",
       " 'S2_t12_NDRE',\n",
       " 'S2_t0_NDVI',\n",
       " 'S2_t1_NDVI',\n",
       " 'S2_t2_NDVI',\n",
       " 'S2_t3_NDVI',\n",
       " 'S2_t4_NDVI',\n",
       " 'S2_t5_NDVI',\n",
       " 'S2_t6_NDVI',\n",
       " 'S2_t7_NDVI',\n",
       " 'S2_t8_NDVI',\n",
       " 'S2_t9_NDVI',\n",
       " 'S2_t10_NDVI',\n",
       " 'S2_t11_NDVI',\n",
       " 'S2_t12_NDVI',\n",
       " 'S2_t0_SAVI',\n",
       " 'S2_t1_SAVI',\n",
       " 'S2_t2_SAVI',\n",
       " 'S2_t3_SAVI',\n",
       " 'S2_t4_SAVI',\n",
       " 'S2_t5_SAVI',\n",
       " 'S2_t6_SAVI',\n",
       " 'S2_t7_SAVI',\n",
       " 'S2_t8_SAVI',\n",
       " 'S2_t9_SAVI',\n",
       " 'S2_t10_SAVI',\n",
       " 'S2_t11_SAVI',\n",
       " 'S2_t12_SAVI']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_columns = [item for sublist in li_bands for item in sublist]\n",
    "relevant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2b1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_columns.append('Crop')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "13501c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[relevant_columns].dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a723b454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Crop\n",
       "Maize     1708212\n",
       "Wheat      234748\n",
       "Others      46119\n",
       "Potato      32851\n",
       "Rice        20604\n",
       "Bean        11138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Crop'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98610d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df['Crop'] == 'Others', 'class'] = 0\n",
    "df.loc[df['Crop'] == 'Maize', 'class'] = 1\n",
    "df.loc[df['Crop'] == 'Wheat', 'class'] = 2\n",
    "df.loc[df['Crop'] == 'Potato', 'class'] = 3\n",
    "df.loc[df['Crop'] == 'Rice', 'class'] = 4\n",
    "df.loc[df['Crop'] == 'Bean', 'class'] = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "27967f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# {0:'Others', 1:'Mazie', 2:'Wheat', 3:'Potato', 4:'Rice', 5:'Bean'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea423aea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['S2_t0_B3',\n",
       " 'S2_t1_B3',\n",
       " 'S2_t2_B3',\n",
       " 'S2_t3_B3',\n",
       " 'S2_t4_B3',\n",
       " 'S2_t5_B3',\n",
       " 'S2_t6_B3',\n",
       " 'S2_t7_B3',\n",
       " 'S2_t8_B3',\n",
       " 'S2_t9_B3',\n",
       " 'S2_t10_B3',\n",
       " 'S2_t11_B3',\n",
       " 'S2_t12_B3',\n",
       " 'S2_t0_B4',\n",
       " 'S2_t1_B4',\n",
       " 'S2_t2_B4',\n",
       " 'S2_t3_B4',\n",
       " 'S2_t4_B4',\n",
       " 'S2_t5_B4',\n",
       " 'S2_t6_B4',\n",
       " 'S2_t7_B4',\n",
       " 'S2_t8_B4',\n",
       " 'S2_t9_B4',\n",
       " 'S2_t10_B4',\n",
       " 'S2_t11_B4',\n",
       " 'S2_t12_B4',\n",
       " 'S2_t0_B5',\n",
       " 'S2_t1_B5',\n",
       " 'S2_t2_B5',\n",
       " 'S2_t3_B5',\n",
       " 'S2_t4_B5',\n",
       " 'S2_t5_B5',\n",
       " 'S2_t6_B5',\n",
       " 'S2_t7_B5',\n",
       " 'S2_t8_B5',\n",
       " 'S2_t9_B5',\n",
       " 'S2_t10_B5',\n",
       " 'S2_t11_B5',\n",
       " 'S2_t12_B5',\n",
       " 'S2_t0_B6',\n",
       " 'S2_t1_B6',\n",
       " 'S2_t2_B6',\n",
       " 'S2_t3_B6',\n",
       " 'S2_t4_B6',\n",
       " 'S2_t5_B6',\n",
       " 'S2_t6_B6',\n",
       " 'S2_t7_B6',\n",
       " 'S2_t8_B6',\n",
       " 'S2_t9_B6',\n",
       " 'S2_t10_B6',\n",
       " 'S2_t11_B6',\n",
       " 'S2_t12_B6',\n",
       " 'S2_t0_B7',\n",
       " 'S2_t1_B7',\n",
       " 'S2_t2_B7',\n",
       " 'S2_t3_B7',\n",
       " 'S2_t4_B7',\n",
       " 'S2_t5_B7',\n",
       " 'S2_t6_B7',\n",
       " 'S2_t7_B7',\n",
       " 'S2_t8_B7',\n",
       " 'S2_t9_B7',\n",
       " 'S2_t10_B7',\n",
       " 'S2_t11_B7',\n",
       " 'S2_t12_B7',\n",
       " 'S2_t0_B8',\n",
       " 'S2_t1_B8',\n",
       " 'S2_t2_B8',\n",
       " 'S2_t3_B8',\n",
       " 'S2_t4_B8',\n",
       " 'S2_t5_B8',\n",
       " 'S2_t6_B8',\n",
       " 'S2_t7_B8',\n",
       " 'S2_t8_B8',\n",
       " 'S2_t9_B8',\n",
       " 'S2_t10_B8',\n",
       " 'S2_t11_B8',\n",
       " 'S2_t12_B8',\n",
       " 'S2_t0_B11',\n",
       " 'S2_t1_B11',\n",
       " 'S2_t2_B11',\n",
       " 'S2_t3_B11',\n",
       " 'S2_t4_B11',\n",
       " 'S2_t5_B11',\n",
       " 'S2_t6_B11',\n",
       " 'S2_t7_B11',\n",
       " 'S2_t8_B11',\n",
       " 'S2_t9_B11',\n",
       " 'S2_t10_B11',\n",
       " 'S2_t11_B11',\n",
       " 'S2_t12_B11',\n",
       " 'S2_t0_B12',\n",
       " 'S2_t1_B12',\n",
       " 'S2_t2_B12',\n",
       " 'S2_t3_B12',\n",
       " 'S2_t4_B12',\n",
       " 'S2_t5_B12',\n",
       " 'S2_t6_B12',\n",
       " 'S2_t7_B12',\n",
       " 'S2_t8_B12',\n",
       " 'S2_t9_B12',\n",
       " 'S2_t10_B12',\n",
       " 'S2_t11_B12',\n",
       " 'S2_t12_B12',\n",
       " 'S2_t0_B8A',\n",
       " 'S2_t1_B8A',\n",
       " 'S2_t2_B8A',\n",
       " 'S2_t3_B8A',\n",
       " 'S2_t4_B8A',\n",
       " 'S2_t5_B8A',\n",
       " 'S2_t6_B8A',\n",
       " 'S2_t7_B8A',\n",
       " 'S2_t8_B8A',\n",
       " 'S2_t9_B8A',\n",
       " 'S2_t10_B8A',\n",
       " 'S2_t11_B8A',\n",
       " 'S2_t12_B8A',\n",
       " 'S2_t0_BSI',\n",
       " 'S2_t1_BSI',\n",
       " 'S2_t2_BSI',\n",
       " 'S2_t3_BSI',\n",
       " 'S2_t4_BSI',\n",
       " 'S2_t5_BSI',\n",
       " 'S2_t6_BSI',\n",
       " 'S2_t7_BSI',\n",
       " 'S2_t8_BSI',\n",
       " 'S2_t9_BSI',\n",
       " 'S2_t10_BSI',\n",
       " 'S2_t11_BSI',\n",
       " 'S2_t12_BSI',\n",
       " 'S2_t0_GCVI',\n",
       " 'S2_t1_GCVI',\n",
       " 'S2_t2_GCVI',\n",
       " 'S2_t3_GCVI',\n",
       " 'S2_t4_GCVI',\n",
       " 'S2_t5_GCVI',\n",
       " 'S2_t6_GCVI',\n",
       " 'S2_t7_GCVI',\n",
       " 'S2_t8_GCVI',\n",
       " 'S2_t9_GCVI',\n",
       " 'S2_t10_GCVI',\n",
       " 'S2_t11_GCVI',\n",
       " 'S2_t12_GCVI',\n",
       " 'S2_t0_LSWI',\n",
       " 'S2_t1_LSWI',\n",
       " 'S2_t2_LSWI',\n",
       " 'S2_t3_LSWI',\n",
       " 'S2_t4_LSWI',\n",
       " 'S2_t5_LSWI',\n",
       " 'S2_t6_LSWI',\n",
       " 'S2_t7_LSWI',\n",
       " 'S2_t8_LSWI',\n",
       " 'S2_t9_LSWI',\n",
       " 'S2_t10_LSWI',\n",
       " 'S2_t11_LSWI',\n",
       " 'S2_t12_LSWI',\n",
       " 'S2_t0_NDRE',\n",
       " 'S2_t1_NDRE',\n",
       " 'S2_t2_NDRE',\n",
       " 'S2_t3_NDRE',\n",
       " 'S2_t4_NDRE',\n",
       " 'S2_t5_NDRE',\n",
       " 'S2_t6_NDRE',\n",
       " 'S2_t7_NDRE',\n",
       " 'S2_t8_NDRE',\n",
       " 'S2_t9_NDRE',\n",
       " 'S2_t10_NDRE',\n",
       " 'S2_t11_NDRE',\n",
       " 'S2_t12_NDRE',\n",
       " 'S2_t0_NDVI',\n",
       " 'S2_t1_NDVI',\n",
       " 'S2_t2_NDVI',\n",
       " 'S2_t3_NDVI',\n",
       " 'S2_t4_NDVI',\n",
       " 'S2_t5_NDVI',\n",
       " 'S2_t6_NDVI',\n",
       " 'S2_t7_NDVI',\n",
       " 'S2_t8_NDVI',\n",
       " 'S2_t9_NDVI',\n",
       " 'S2_t10_NDVI',\n",
       " 'S2_t11_NDVI',\n",
       " 'S2_t12_NDVI',\n",
       " 'S2_t0_SAVI',\n",
       " 'S2_t1_SAVI',\n",
       " 'S2_t2_SAVI',\n",
       " 'S2_t3_SAVI',\n",
       " 'S2_t4_SAVI',\n",
       " 'S2_t5_SAVI',\n",
       " 'S2_t6_SAVI',\n",
       " 'S2_t7_SAVI',\n",
       " 'S2_t8_SAVI',\n",
       " 'S2_t9_SAVI',\n",
       " 'S2_t10_SAVI',\n",
       " 'S2_t11_SAVI',\n",
       " 'S2_t12_SAVI']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_columns = [item for sublist in li_bands for item in sublist]\n",
    "# relevant_columns.append('class')\n",
    "relevant_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4e0c7135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class\n",
       "1.0    1708212\n",
       "2.0     234748\n",
       "0.0      46119\n",
       "3.0      32851\n",
       "4.0      20604\n",
       "5.0      11138\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3e4fc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[relevant_columns]\n",
    "Y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9989be7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ef7fdfee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train columns\n",
      "['S2_t0_B3', 'S2_t1_B3', 'S2_t2_B3', 'S2_t3_B3', 'S2_t4_B3', 'S2_t5_B3', 'S2_t6_B3', 'S2_t7_B3', 'S2_t8_B3', 'S2_t9_B3', 'S2_t10_B3', 'S2_t11_B3', 'S2_t12_B3']\n",
      "['S2_t0_B4', 'S2_t1_B4', 'S2_t2_B4', 'S2_t3_B4', 'S2_t4_B4', 'S2_t5_B4', 'S2_t6_B4', 'S2_t7_B4', 'S2_t8_B4', 'S2_t9_B4', 'S2_t10_B4', 'S2_t11_B4', 'S2_t12_B4']\n",
      "['S2_t0_B5', 'S2_t1_B5', 'S2_t2_B5', 'S2_t3_B5', 'S2_t4_B5', 'S2_t5_B5', 'S2_t6_B5', 'S2_t7_B5', 'S2_t8_B5', 'S2_t9_B5', 'S2_t10_B5', 'S2_t11_B5', 'S2_t12_B5']\n",
      "['S2_t0_B6', 'S2_t1_B6', 'S2_t2_B6', 'S2_t3_B6', 'S2_t4_B6', 'S2_t5_B6', 'S2_t6_B6', 'S2_t7_B6', 'S2_t8_B6', 'S2_t9_B6', 'S2_t10_B6', 'S2_t11_B6', 'S2_t12_B6']\n",
      "['S2_t0_B7', 'S2_t1_B7', 'S2_t2_B7', 'S2_t3_B7', 'S2_t4_B7', 'S2_t5_B7', 'S2_t6_B7', 'S2_t7_B7', 'S2_t8_B7', 'S2_t9_B7', 'S2_t10_B7', 'S2_t11_B7', 'S2_t12_B7']\n",
      "['S2_t0_B8', 'S2_t1_B8', 'S2_t2_B8', 'S2_t3_B8', 'S2_t4_B8', 'S2_t5_B8', 'S2_t6_B8', 'S2_t7_B8', 'S2_t8_B8', 'S2_t9_B8', 'S2_t10_B8', 'S2_t11_B8', 'S2_t12_B8']\n",
      "['S2_t0_B11', 'S2_t1_B11', 'S2_t2_B11', 'S2_t3_B11', 'S2_t4_B11', 'S2_t5_B11', 'S2_t6_B11', 'S2_t7_B11', 'S2_t8_B11', 'S2_t9_B11', 'S2_t10_B11', 'S2_t11_B11', 'S2_t12_B11']\n",
      "['S2_t0_B12', 'S2_t1_B12', 'S2_t2_B12', 'S2_t3_B12', 'S2_t4_B12', 'S2_t5_B12', 'S2_t6_B12', 'S2_t7_B12', 'S2_t8_B12', 'S2_t9_B12', 'S2_t10_B12', 'S2_t11_B12', 'S2_t12_B12']\n",
      "['S2_t0_B8A', 'S2_t1_B8A', 'S2_t2_B8A', 'S2_t3_B8A', 'S2_t4_B8A', 'S2_t5_B8A', 'S2_t6_B8A', 'S2_t7_B8A', 'S2_t8_B8A', 'S2_t9_B8A', 'S2_t10_B8A', 'S2_t11_B8A', 'S2_t12_B8A']\n",
      "['S2_t0_BSI', 'S2_t1_BSI', 'S2_t2_BSI', 'S2_t3_BSI', 'S2_t4_BSI', 'S2_t5_BSI', 'S2_t6_BSI', 'S2_t7_BSI', 'S2_t8_BSI', 'S2_t9_BSI', 'S2_t10_BSI', 'S2_t11_BSI', 'S2_t12_BSI']\n",
      "['S2_t0_GCVI', 'S2_t1_GCVI', 'S2_t2_GCVI', 'S2_t3_GCVI', 'S2_t4_GCVI', 'S2_t5_GCVI', 'S2_t6_GCVI', 'S2_t7_GCVI', 'S2_t8_GCVI', 'S2_t9_GCVI', 'S2_t10_GCVI', 'S2_t11_GCVI', 'S2_t12_GCVI']\n",
      "['S2_t0_LSWI', 'S2_t1_LSWI', 'S2_t2_LSWI', 'S2_t3_LSWI', 'S2_t4_LSWI', 'S2_t5_LSWI', 'S2_t6_LSWI', 'S2_t7_LSWI', 'S2_t8_LSWI', 'S2_t9_LSWI', 'S2_t10_LSWI', 'S2_t11_LSWI', 'S2_t12_LSWI']\n",
      "['S2_t0_NDRE', 'S2_t1_NDRE', 'S2_t2_NDRE', 'S2_t3_NDRE', 'S2_t4_NDRE', 'S2_t5_NDRE', 'S2_t6_NDRE', 'S2_t7_NDRE', 'S2_t8_NDRE', 'S2_t9_NDRE', 'S2_t10_NDRE', 'S2_t11_NDRE', 'S2_t12_NDRE']\n",
      "['S2_t0_NDVI', 'S2_t1_NDVI', 'S2_t2_NDVI', 'S2_t3_NDVI', 'S2_t4_NDVI', 'S2_t5_NDVI', 'S2_t6_NDVI', 'S2_t7_NDVI', 'S2_t8_NDVI', 'S2_t9_NDVI', 'S2_t10_NDVI', 'S2_t11_NDVI', 'S2_t12_NDVI']\n",
      "['S2_t0_SAVI', 'S2_t1_SAVI', 'S2_t2_SAVI', 'S2_t3_SAVI', 'S2_t4_SAVI', 'S2_t5_SAVI', 'S2_t6_SAVI', 'S2_t7_SAVI', 'S2_t8_SAVI', 'S2_t9_SAVI', 'S2_t10_SAVI', 'S2_t11_SAVI', 'S2_t12_SAVI']\n",
      "(2053672, 13, 15)\n"
     ]
    }
   ],
   "source": [
    "def create_dataset(df):\n",
    "    data = []\n",
    "    for b in bands:\n",
    "        bnd = [col for col in relevant_columns if col.endswith(b)]\n",
    "        print(bnd)\n",
    "        data.append(df[bnd].values)\n",
    "    dataset = np.stack(data, axis=2)\n",
    "    return dataset\n",
    "print('Train columns')\n",
    "train_dataset = create_dataset(X)\n",
    "print(train_dataset.shape)\n",
    "# print('Test columns')\n",
    "# val_dataset = create_dataset(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e79ca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2053672"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f0367acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = Y.to_numpy().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ecce2aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.data[idx], dtype=torch.float), torch.tensor(self.labels[idx], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1f6711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MyDataset(train_dataset, train_labels) \n",
    "# test_dataset = MyDataset(val_dataset, test_labels)\n",
    "batch_size = 1024\n",
    "epochs = 10\n",
    "lr = 0.01\n",
    "weight_decay = 1e-4\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a0e933",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from models import LSTM\n",
    "import time\n",
    "\n",
    "def train(model, train_dataset, batch_size, epochs, lr, weight_decay, device):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        epoch_loss = 0.0\n",
    "        epoch_correct = 0\n",
    "        epoch_total = 0\n",
    "        \n",
    "        model.train()  # Set model to training mode\n",
    "        \n",
    "        print(f\"Starting epoch {epoch+1}/{epochs}\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            epoch_correct += (predicted == labels).sum().item()\n",
    "            epoch_total += labels.size(0)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            if batch_idx % 100 == 0:\n",
    "                print(f\"Epoch [{epoch+1}/{epochs}], Batch [{batch_idx}/{len(train_loader)}], Loss: {loss.item():.4f}\")\n",
    "        \n",
    "        end_time = time.time()\n",
    "        epoch_time = end_time - start_time\n",
    "        \n",
    "        print('Epoch [{}/{}], Loss: {:.4f}, Accuracy: {:.2f}%, Time: {:.2f} seconds'\n",
    "              .format(epoch+1, epochs, epoch_loss, 100*epoch_correct/epoch_total, epoch_time))\n",
    "        \n",
    "        \n",
    "        train_losses.append(epoch_loss)\n",
    "        train_accs.append(100*epoch_correct/epoch_total)\n",
    "    \n",
    "    # plot loss curve\n",
    "    plt.plot(np.arange(epochs), train_losses)\n",
    "    plt.title(\"Training Loss Curve\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.savefig('Model_loss.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    return model, train_losses, train_accs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5cff2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8db7f9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1/10\n",
      "Epoch [1/10], Batch [0/2006], Loss: 1.6470\n",
      "Epoch [1/10], Batch [100/2006], Loss: 0.3924\n",
      "Epoch [1/10], Batch [200/2006], Loss: 0.2814\n",
      "Epoch [1/10], Batch [300/2006], Loss: 0.2157\n",
      "Epoch [1/10], Batch [400/2006], Loss: 0.1410\n",
      "Epoch [1/10], Batch [500/2006], Loss: 0.1086\n",
      "Epoch [1/10], Batch [600/2006], Loss: 0.1130\n",
      "Epoch [1/10], Batch [700/2006], Loss: 0.0532\n",
      "Epoch [1/10], Batch [800/2006], Loss: 0.0761\n",
      "Epoch [1/10], Batch [900/2006], Loss: 0.0922\n",
      "Epoch [1/10], Batch [1000/2006], Loss: 0.0785\n",
      "Epoch [1/10], Batch [1100/2006], Loss: 0.0539\n",
      "Epoch [1/10], Batch [1200/2006], Loss: 0.0421\n",
      "Epoch [1/10], Batch [1300/2006], Loss: 0.0530\n",
      "Epoch [1/10], Batch [1400/2006], Loss: 0.0582\n",
      "Epoch [1/10], Batch [1500/2006], Loss: 0.0611\n",
      "Epoch [1/10], Batch [1600/2006], Loss: 0.0489\n",
      "Epoch [1/10], Batch [1700/2006], Loss: 0.0451\n",
      "Epoch [1/10], Batch [1800/2006], Loss: 0.0351\n",
      "Epoch [1/10], Batch [1900/2006], Loss: 0.0552\n",
      "Epoch [1/10], Batch [2000/2006], Loss: 0.0554\n",
      "Epoch [1/10], Loss: 279.4885, Accuracy: 96.06%, Time: 223.81 seconds\n",
      "Starting epoch 2/10\n",
      "Epoch [2/10], Batch [0/2006], Loss: 0.0492\n",
      "Epoch [2/10], Batch [100/2006], Loss: 0.0392\n",
      "Epoch [2/10], Batch [200/2006], Loss: 0.0492\n",
      "Epoch [2/10], Batch [300/2006], Loss: 0.0273\n",
      "Epoch [2/10], Batch [400/2006], Loss: 0.0440\n",
      "Epoch [2/10], Batch [500/2006], Loss: 0.0299\n",
      "Epoch [2/10], Batch [600/2006], Loss: 0.0349\n",
      "Epoch [2/10], Batch [700/2006], Loss: 0.0363\n",
      "Epoch [2/10], Batch [800/2006], Loss: 0.0333\n",
      "Epoch [2/10], Batch [900/2006], Loss: 0.0306\n",
      "Epoch [2/10], Batch [1000/2006], Loss: 0.0212\n",
      "Epoch [2/10], Batch [1100/2006], Loss: 0.0347\n",
      "Epoch [2/10], Batch [1200/2006], Loss: 0.0361\n",
      "Epoch [2/10], Batch [1300/2006], Loss: 0.0429\n",
      "Epoch [2/10], Batch [1400/2006], Loss: 0.0378\n",
      "Epoch [2/10], Batch [1500/2006], Loss: 0.0257\n",
      "Epoch [2/10], Batch [1600/2006], Loss: 0.0225\n",
      "Epoch [2/10], Batch [1700/2006], Loss: 0.0245\n",
      "Epoch [2/10], Batch [1800/2006], Loss: 0.0255\n",
      "Epoch [2/10], Batch [1900/2006], Loss: 0.0235\n",
      "Epoch [2/10], Batch [2000/2006], Loss: 0.0445\n",
      "Epoch [2/10], Loss: 65.6731, Accuracy: 98.92%, Time: 224.95 seconds\n",
      "Starting epoch 3/10\n",
      "Epoch [3/10], Batch [0/2006], Loss: 0.0433\n",
      "Epoch [3/10], Batch [100/2006], Loss: 0.0224\n",
      "Epoch [3/10], Batch [200/2006], Loss: 0.0264\n",
      "Epoch [3/10], Batch [300/2006], Loss: 0.0273\n",
      "Epoch [3/10], Batch [400/2006], Loss: 0.0274\n",
      "Epoch [3/10], Batch [500/2006], Loss: 0.0141\n",
      "Epoch [3/10], Batch [600/2006], Loss: 0.0151\n",
      "Epoch [3/10], Batch [700/2006], Loss: 0.0275\n",
      "Epoch [3/10], Batch [800/2006], Loss: 0.0270\n",
      "Epoch [3/10], Batch [900/2006], Loss: 0.0257\n",
      "Epoch [3/10], Batch [1000/2006], Loss: 0.0181\n",
      "Epoch [3/10], Batch [1100/2006], Loss: 0.0396\n",
      "Epoch [3/10], Batch [1200/2006], Loss: 0.0101\n",
      "Epoch [3/10], Batch [1300/2006], Loss: 0.0331\n",
      "Epoch [3/10], Batch [1400/2006], Loss: 0.0156\n",
      "Epoch [3/10], Batch [1500/2006], Loss: 0.0406\n",
      "Epoch [3/10], Batch [1600/2006], Loss: 0.0226\n",
      "Epoch [3/10], Batch [1700/2006], Loss: 0.0272\n",
      "Epoch [3/10], Batch [1800/2006], Loss: 0.0266\n",
      "Epoch [3/10], Batch [1900/2006], Loss: 0.0314\n",
      "Epoch [3/10], Batch [2000/2006], Loss: 0.0373\n",
      "Epoch [3/10], Loss: 51.4968, Accuracy: 99.16%, Time: 225.52 seconds\n",
      "Starting epoch 4/10\n",
      "Epoch [4/10], Batch [0/2006], Loss: 0.0259\n",
      "Epoch [4/10], Batch [100/2006], Loss: 0.0165\n",
      "Epoch [4/10], Batch [200/2006], Loss: 0.0165\n",
      "Epoch [4/10], Batch [300/2006], Loss: 0.0305\n",
      "Epoch [4/10], Batch [400/2006], Loss: 0.0221\n",
      "Epoch [4/10], Batch [500/2006], Loss: 0.0210\n",
      "Epoch [4/10], Batch [600/2006], Loss: 0.0161\n",
      "Epoch [4/10], Batch [700/2006], Loss: 0.0149\n",
      "Epoch [4/10], Batch [800/2006], Loss: 0.0349\n",
      "Epoch [4/10], Batch [900/2006], Loss: 0.0114\n",
      "Epoch [4/10], Batch [1000/2006], Loss: 0.0115\n",
      "Epoch [4/10], Batch [1100/2006], Loss: 0.0143\n",
      "Epoch [4/10], Batch [1200/2006], Loss: 0.0271\n",
      "Epoch [4/10], Batch [1300/2006], Loss: 0.0253\n",
      "Epoch [4/10], Batch [1400/2006], Loss: 0.0264\n",
      "Epoch [4/10], Batch [1500/2006], Loss: 0.0136\n",
      "Epoch [4/10], Batch [1600/2006], Loss: 0.0128\n",
      "Epoch [4/10], Batch [1700/2006], Loss: 0.0280\n",
      "Epoch [4/10], Batch [1800/2006], Loss: 0.0377\n",
      "Epoch [4/10], Batch [1900/2006], Loss: 0.0168\n",
      "Epoch [4/10], Batch [2000/2006], Loss: 0.0259\n",
      "Epoch [4/10], Loss: 46.2731, Accuracy: 99.25%, Time: 225.75 seconds\n",
      "Starting epoch 5/10\n",
      "Epoch [5/10], Batch [0/2006], Loss: 0.0134\n",
      "Epoch [5/10], Batch [100/2006], Loss: 0.0076\n",
      "Epoch [5/10], Batch [200/2006], Loss: 0.0273\n",
      "Epoch [5/10], Batch [300/2006], Loss: 0.0417\n",
      "Epoch [5/10], Batch [400/2006], Loss: 0.0307\n",
      "Epoch [5/10], Batch [500/2006], Loss: 0.0353\n",
      "Epoch [5/10], Batch [600/2006], Loss: 0.0129\n",
      "Epoch [5/10], Batch [700/2006], Loss: 0.0097\n",
      "Epoch [5/10], Batch [800/2006], Loss: 0.0446\n",
      "Epoch [5/10], Batch [900/2006], Loss: 0.0263\n",
      "Epoch [5/10], Batch [1000/2006], Loss: 0.0209\n",
      "Epoch [5/10], Batch [1100/2006], Loss: 0.0240\n",
      "Epoch [5/10], Batch [1200/2006], Loss: 0.0295\n",
      "Epoch [5/10], Batch [1300/2006], Loss: 0.0239\n",
      "Epoch [5/10], Batch [1400/2006], Loss: 0.0176\n",
      "Epoch [5/10], Batch [1500/2006], Loss: 0.0131\n",
      "Epoch [5/10], Batch [1600/2006], Loss: 0.0113\n",
      "Epoch [5/10], Batch [1700/2006], Loss: 0.0226\n",
      "Epoch [5/10], Batch [1800/2006], Loss: 0.0236\n",
      "Epoch [5/10], Batch [1900/2006], Loss: 0.0439\n",
      "Epoch [5/10], Batch [2000/2006], Loss: 0.0156\n",
      "Epoch [5/10], Loss: 43.8282, Accuracy: 99.29%, Time: 225.67 seconds\n",
      "Starting epoch 6/10\n",
      "Epoch [6/10], Batch [0/2006], Loss: 0.0250\n",
      "Epoch [6/10], Batch [100/2006], Loss: 0.0298\n",
      "Epoch [6/10], Batch [200/2006], Loss: 0.0257\n",
      "Epoch [6/10], Batch [300/2006], Loss: 0.0220\n",
      "Epoch [6/10], Batch [400/2006], Loss: 0.0236\n",
      "Epoch [6/10], Batch [500/2006], Loss: 0.0148\n",
      "Epoch [6/10], Batch [600/2006], Loss: 0.0211\n",
      "Epoch [6/10], Batch [700/2006], Loss: 0.0086\n",
      "Epoch [6/10], Batch [800/2006], Loss: 0.0187\n",
      "Epoch [6/10], Batch [900/2006], Loss: 0.0253\n",
      "Epoch [6/10], Batch [1000/2006], Loss: 0.0188\n",
      "Epoch [6/10], Batch [1100/2006], Loss: 0.0256\n",
      "Epoch [6/10], Batch [1200/2006], Loss: 0.0145\n",
      "Epoch [6/10], Batch [1300/2006], Loss: 0.0188\n",
      "Epoch [6/10], Batch [1400/2006], Loss: 0.0272\n",
      "Epoch [6/10], Batch [1500/2006], Loss: 0.0210\n",
      "Epoch [6/10], Batch [1600/2006], Loss: 0.0093\n",
      "Epoch [6/10], Batch [1700/2006], Loss: 0.0224\n",
      "Epoch [6/10], Batch [1800/2006], Loss: 0.0175\n",
      "Epoch [6/10], Batch [1900/2006], Loss: 0.0110\n",
      "Epoch [6/10], Batch [2000/2006], Loss: 0.0193\n",
      "Epoch [6/10], Loss: 42.4235, Accuracy: 99.31%, Time: 225.54 seconds\n",
      "Starting epoch 7/10\n",
      "Epoch [7/10], Batch [0/2006], Loss: 0.0106\n",
      "Epoch [7/10], Batch [100/2006], Loss: 0.0221\n",
      "Epoch [7/10], Batch [200/2006], Loss: 0.0243\n",
      "Epoch [7/10], Batch [300/2006], Loss: 0.0359\n",
      "Epoch [7/10], Batch [400/2006], Loss: 0.0178\n",
      "Epoch [7/10], Batch [500/2006], Loss: 0.0138\n",
      "Epoch [7/10], Batch [600/2006], Loss: 0.0227\n",
      "Epoch [7/10], Batch [700/2006], Loss: 0.0195\n",
      "Epoch [7/10], Batch [800/2006], Loss: 0.0114\n",
      "Epoch [7/10], Batch [900/2006], Loss: 0.0200\n",
      "Epoch [7/10], Batch [1000/2006], Loss: 0.0152\n",
      "Epoch [7/10], Batch [1100/2006], Loss: 0.0203\n",
      "Epoch [7/10], Batch [1200/2006], Loss: 0.0168\n",
      "Epoch [7/10], Batch [1300/2006], Loss: 0.0175\n",
      "Epoch [7/10], Batch [1400/2006], Loss: 0.0253\n",
      "Epoch [7/10], Batch [1500/2006], Loss: 0.0186\n",
      "Epoch [7/10], Batch [1600/2006], Loss: 0.0155\n",
      "Epoch [7/10], Batch [1700/2006], Loss: 0.0212\n",
      "Epoch [7/10], Batch [1800/2006], Loss: 0.0211\n",
      "Epoch [7/10], Batch [1900/2006], Loss: 0.0250\n",
      "Epoch [7/10], Batch [2000/2006], Loss: 0.0133\n",
      "Epoch [7/10], Loss: 40.4943, Accuracy: 99.35%, Time: 225.75 seconds\n",
      "Starting epoch 8/10\n",
      "Epoch [8/10], Batch [0/2006], Loss: 0.0264\n",
      "Epoch [8/10], Batch [100/2006], Loss: 0.0190\n",
      "Epoch [8/10], Batch [200/2006], Loss: 0.0089\n",
      "Epoch [8/10], Batch [300/2006], Loss: 0.0256\n",
      "Epoch [8/10], Batch [400/2006], Loss: 0.0209\n",
      "Epoch [8/10], Batch [500/2006], Loss: 0.0221\n",
      "Epoch [8/10], Batch [600/2006], Loss: 0.0184\n",
      "Epoch [8/10], Batch [700/2006], Loss: 0.0054\n",
      "Epoch [8/10], Batch [800/2006], Loss: 0.0154\n",
      "Epoch [8/10], Batch [900/2006], Loss: 0.0177\n",
      "Epoch [8/10], Batch [1000/2006], Loss: 0.0164\n",
      "Epoch [8/10], Batch [1100/2006], Loss: 0.0233\n",
      "Epoch [8/10], Batch [1200/2006], Loss: 0.0138\n",
      "Epoch [8/10], Batch [1300/2006], Loss: 0.0231\n",
      "Epoch [8/10], Batch [1400/2006], Loss: 0.0265\n",
      "Epoch [8/10], Batch [1500/2006], Loss: 0.0280\n",
      "Epoch [8/10], Batch [1600/2006], Loss: 0.0189\n",
      "Epoch [8/10], Batch [1700/2006], Loss: 0.0136\n",
      "Epoch [8/10], Batch [1800/2006], Loss: 0.0137\n",
      "Epoch [8/10], Batch [1900/2006], Loss: 0.0189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/10], Batch [2000/2006], Loss: 0.0148\n",
      "Epoch [8/10], Loss: 39.9841, Accuracy: 99.35%, Time: 226.01 seconds\n",
      "Starting epoch 9/10\n",
      "Epoch [9/10], Batch [0/2006], Loss: 0.0230\n",
      "Epoch [9/10], Batch [100/2006], Loss: 0.0230\n",
      "Epoch [9/10], Batch [200/2006], Loss: 0.0160\n",
      "Epoch [9/10], Batch [300/2006], Loss: 0.0185\n",
      "Epoch [9/10], Batch [400/2006], Loss: 0.0194\n",
      "Epoch [9/10], Batch [500/2006], Loss: 0.0159\n",
      "Epoch [9/10], Batch [600/2006], Loss: 0.0212\n",
      "Epoch [9/10], Batch [700/2006], Loss: 0.0396\n",
      "Epoch [9/10], Batch [800/2006], Loss: 0.0224\n",
      "Epoch [9/10], Batch [900/2006], Loss: 0.0086\n",
      "Epoch [9/10], Batch [1000/2006], Loss: 0.0225\n",
      "Epoch [9/10], Batch [1100/2006], Loss: 0.0344\n",
      "Epoch [9/10], Batch [1200/2006], Loss: 0.0120\n",
      "Epoch [9/10], Batch [1300/2006], Loss: 0.0280\n",
      "Epoch [9/10], Batch [1400/2006], Loss: 0.0185\n",
      "Epoch [9/10], Batch [1500/2006], Loss: 0.0321\n",
      "Epoch [9/10], Batch [1600/2006], Loss: 0.0100\n",
      "Epoch [9/10], Batch [1700/2006], Loss: 0.0193\n",
      "Epoch [9/10], Batch [1800/2006], Loss: 0.0102\n",
      "Epoch [9/10], Batch [1900/2006], Loss: 0.0248\n",
      "Epoch [9/10], Batch [2000/2006], Loss: 0.0195\n",
      "Epoch [9/10], Loss: 39.2816, Accuracy: 99.36%, Time: 225.83 seconds\n",
      "Starting epoch 10/10\n",
      "Epoch [10/10], Batch [0/2006], Loss: 0.0194\n",
      "Epoch [10/10], Batch [100/2006], Loss: 0.0180\n",
      "Epoch [10/10], Batch [200/2006], Loss: 0.0276\n",
      "Epoch [10/10], Batch [300/2006], Loss: 0.0183\n",
      "Epoch [10/10], Batch [400/2006], Loss: 0.0253\n",
      "Epoch [10/10], Batch [500/2006], Loss: 0.0267\n",
      "Epoch [10/10], Batch [600/2006], Loss: 0.0276\n",
      "Epoch [10/10], Batch [700/2006], Loss: 0.0393\n",
      "Epoch [10/10], Batch [800/2006], Loss: 0.0250\n",
      "Epoch [10/10], Batch [900/2006], Loss: 0.0278\n",
      "Epoch [10/10], Batch [1000/2006], Loss: 0.0162\n",
      "Epoch [10/10], Batch [1100/2006], Loss: 0.0176\n",
      "Epoch [10/10], Batch [1200/2006], Loss: 0.0110\n",
      "Epoch [10/10], Batch [1300/2006], Loss: 0.0074\n",
      "Epoch [10/10], Batch [1400/2006], Loss: 0.0137\n",
      "Epoch [10/10], Batch [1500/2006], Loss: 0.0217\n",
      "Epoch [10/10], Batch [1600/2006], Loss: 0.0146\n",
      "Epoch [10/10], Batch [1700/2006], Loss: 0.0175\n",
      "Epoch [10/10], Batch [1800/2006], Loss: 0.0179\n",
      "Epoch [10/10], Batch [1900/2006], Loss: 0.0216\n",
      "Epoch [10/10], Batch [2000/2006], Loss: 0.0272\n",
      "Epoch [10/10], Loss: 38.3942, Accuracy: 99.38%, Time: 225.83 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjsAAAHHCAYAAABZbpmkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAABCDElEQVR4nO3deXhU5d3/8c8syWRPyDIJkbAIYV9ENiMu9AFZRFsUH8GiBfWnVoMt4l6rolaptlprqaBPq6gFF6yg0ooiCCqiLIoiKouyBDAJAbPvM+f3RzIDQwiEkOTM8n5d11zM3Oecme8QNR/v5dwWwzAMAQAABCmr2QUAAAC0JsIOAAAIaoQdAAAQ1Ag7AAAgqBF2AABAUCPsAACAoEbYAQAAQY2wAwAAghphBwAABDXCDgBJ0rRp09S5c+dmXTtr1ixZLJaWLQgAWghhB/BzFoulSY9Vq1aZXaoppk2bppiYGLPLaLLFixdr3LhxSk5OVnh4uNLT03X55Zdr5cqVZpcGBC0Le2MB/u1f//qXz+sXX3xRy5cv10svveTTfsEFFyg1NbXZn1NTUyO32y2Hw3HS19bW1qq2tlYRERHN/vzmmjZtml5//XWVlpa2+WefDMMwdM0112j+/PkaOHCgLrvsMqWlpenHH3/U4sWLtXHjRq1Zs0Znn3222aUCQcdudgEAju/KK6/0ef3pp59q+fLlDdqPVl5erqioqCZ/TlhYWLPqkyS73S67nf+cHM/jjz+u+fPna8aMGXriiSd8hv3uuecevfTSSy3yd2gYhiorKxUZGXnK7wUEC4axgCAwYsQI9e3bVxs3btR5552nqKgo/e53v5Mkvfnmmxo/frzS09PlcDjUtWtXPfTQQ3K5XD7vcfScnV27dslisejPf/6znn32WXXt2lUOh0NDhgzR+vXrfa491pwdi8Wi6dOna8mSJerbt68cDof69OmjZcuWNah/1apVGjx4sCIiItS1a1c988wzLT4PaNGiRRo0aJAiIyOVnJysK6+8Uvv27fM5Jzc3V1dffbU6dOggh8Oh9u3b6xe/+IV27drlPWfDhg0aM2aMkpOTFRkZqS5duuiaa6457mdXVFRo9uzZ6tmzp/785z8f83tdddVVGjp0qKTG50DNnz9fFovFp57OnTvroosu0rvvvqvBgwcrMjJSzzzzjPr27auf/exnDd7D7XbrtNNO02WXXebT9uSTT6pPnz6KiIhQamqqbrjhBv3000/H/V5AoOB/xYAgcfDgQY0bN06TJ0/WlVde6R3Smj9/vmJiYjRz5kzFxMRo5cqVuu+++1RcXKw//elPJ3zfhQsXqqSkRDfccIMsFosee+wxXXrppfrhhx9O2Bv08ccf64033tBNN92k2NhYPfXUU5o4caL27NmjpKQkSdIXX3yhsWPHqn379nrggQfkcrn04IMPKiUl5dT/UurNnz9fV199tYYMGaLZs2crLy9Pf/3rX7VmzRp98cUXSkhIkCRNnDhRW7Zs0c0336zOnTsrPz9fy5cv1549e7yvR48erZSUFN11111KSEjQrl279MYbb5zw7+HQoUOaMWOGbDZbi30vj61bt+qKK67QDTfcoOuuu049evTQpEmTNGvWLOXm5iotLc2nlv3792vy5MnethtuuMH7d/Sb3/xGO3fu1Jw5c/TFF19ozZo1p9TrB/gFA0BAyc7ONo7+V/f88883JBnz5s1rcH55eXmDthtuuMGIiooyKisrvW1Tp041OnXq5H29c+dOQ5KRlJRkHDp0yNv+5ptvGpKMt99+29t2//33N6hJkhEeHm7s2LHD2/bll18akoy//e1v3raLL77YiIqKMvbt2+dt2759u2G32xu857FMnTrViI6ObvR4dXW14XQ6jb59+xoVFRXe9qVLlxqSjPvuu88wDMP46aefDEnGn/70p0bfa/HixYYkY/369Ses60h//etfDUnG4sWLm3T+sf4+DcMwnn/+eUOSsXPnTm9bp06dDEnGsmXLfM7dunVrg79rwzCMm266yYiJifH+c/HRRx8ZkowFCxb4nLds2bJjtgOBiGEsIEg4HA5dffXVDdqPnLtRUlKigoICnXvuuSovL9d33313wvedNGmS2rVr53197rnnSpJ++OGHE147atQode3a1fu6f//+iouL817rcrn0/vvva8KECUpPT/ee161bN40bN+6E798UGzZsUH5+vm666SafCdTjx49Xz5499Z///EdS3d9TeHi4Vq1a1ejwjacHaOnSpaqpqWlyDcXFxZKk2NjYZn6L4+vSpYvGjBnj09a9e3edccYZevXVV71tLpdLr7/+ui6++GLvPxeLFi1SfHy8LrjgAhUUFHgfgwYNUkxMjD744INWqRloS4QdIEicdtppCg8Pb9C+ZcsWXXLJJYqPj1dcXJxSUlK8k5uLiopO+L4dO3b0ee0JPk2Zz3H0tZ7rPdfm5+eroqJC3bp1a3DesdqaY/fu3ZKkHj16NDjWs2dP73GHw6FHH31U77zzjlJTU3XeeefpscceU25urvf8888/XxMnTtQDDzyg5ORk/eIXv9Dzzz+vqqqq49YQFxcnqS5stoYuXbocs33SpElas2aNd27SqlWrlJ+fr0mTJnnP2b59u4qKiuR0OpWSkuLzKC0tVX5+fqvUDLQlwg4QJI61+qawsFDnn3++vvzySz344IN6++23tXz5cj366KOS6iamnkhjc0yMJty14lSuNcOMGTO0bds2zZ49WxEREbr33nvVq1cvffHFF5LqJl2//vrrWrt2raZPn659+/bpmmuu0aBBg4679L1nz56SpM2bNzepjsYmZh89qdyjsZVXkyZNkmEYWrRokSTptddeU3x8vMaOHes9x+12y+l0avny5cd8PPjgg02qGfBnhB0giK1atUoHDx7U/Pnz9dvf/lYXXXSRRo0a5TMsZSan06mIiAjt2LGjwbFjtTVHp06dJNVN4j3a1q1bvcc9unbtqltvvVXvvfeevv76a1VXV+vxxx/3Oeess87Sww8/rA0bNmjBggXasmWLXnnllUZrOOecc9SuXTu9/PLLjQaWI3l+PoWFhT7tnl6opurSpYuGDh2qV199VbW1tXrjjTc0YcIEn3spde3aVQcPHtTw4cM1atSoBo8BAwac1GcC/oiwAwQxT8/KkT0p1dXVevrpp80qyYfNZtOoUaO0ZMkS7d+/39u+Y8cOvfPOOy3yGYMHD5bT6dS8efN8hpveeecdffvttxo/frykuvsSVVZW+lzbtWtXxcbGeq/76aefGvRKnXHGGZJ03KGsqKgo3Xnnnfr222915513HrNn61//+pfWrVvn/VxJ+vDDD73Hy8rK9MILLzT1a3tNmjRJn376qZ577jkVFBT4DGFJ0uWXXy6Xy6WHHnqowbW1tbUNAhcQiFh6DgSxs88+W+3atdPUqVP1m9/8RhaLRS+99JJfDSPNmjVL7733noYPH64bb7xRLpdLc+bMUd++fbVp06YmvUdNTY3+8Ic/NGhPTEzUTTfdpEcffVRXX321zj//fF1xxRXepeedO3fWLbfcIknatm2bRo4cqcsvv1y9e/eW3W7X4sWLlZeX512m/cILL+jpp5/WJZdcoq5du6qkpET/93//p7i4OF144YXHrfH222/Xli1b9Pjjj+uDDz7w3kE5NzdXS5Ys0bp16/TJJ59IkkaPHq2OHTvq2muv1e233y6bzabnnntOKSkp2rNnz0n87daFmdtuu0233XabEhMTNWrUKJ/j559/vm644QbNnj1bmzZt0ujRoxUWFqbt27dr0aJF+utf/+pzTx4gIJm4EgxAMzS29LxPnz7HPH/NmjXGWWedZURGRhrp6enGHXfcYbz77ruGJOODDz7wntfY0vNjLcWWZNx///3e140tPc/Ozm5wbadOnYypU6f6tK1YscIYOHCgER4ebnTt2tX4xz/+Ydx6661GREREI38Lh02dOtWQdMxH165dvee9+uqrxsCBAw2Hw2EkJiYaU6ZMMfbu3es9XlBQYGRnZxs9e/Y0oqOjjfj4eGPYsGHGa6+95j3n888/N6644gqjY8eOhsPhMJxOp3HRRRcZGzZsOGGdHq+//roxevRoIzEx0bDb7Ub79u2NSZMmGatWrfI5b+PGjcawYcOM8PBwo2PHjsYTTzzR6NLz8ePHH/czhw8fbkgy/t//+3+NnvPss88agwYNMiIjI43Y2FijX79+xh133GHs37+/yd8N8FfsjQXAL02YMEFbtmzR9u3bzS4FQIBjzg4A01VUVPi83r59u/773/9qxIgR5hQEIKjQswPAdO3bt9e0adN0+umna/fu3Zo7d66qqqr0xRdfKDMz0+zyAAQ4JigDMN3YsWP18ssvKzc3Vw6HQ1lZWXrkkUcIOgBaBD07AAAgqDFnBwAABDXCDgAACGrM2VHd3jD79+9XbGxso3vSAAAA/2IYhkpKSpSeni6rtfH+G8KOpP379ysjI8PsMgAAQDPk5OSoQ4cOjR4n7EiKjY2VVPeXFRcXZ3I1AACgKYqLi5WRkeH9Pd4Ywo7kHbqKi4sj7AAAEGBONAWFCcoAACCoEXYAAEBQI+wAAICgRtgBAABBjbADAACCGmEHAAAENcIOAAAIaoQdAAAQ1Ag7AAAgqBF2AABAUCPsAACAoEbYAQAAQY2w04oqa1zasr9I1bVus0sBACBkEXZa0fA/rtT4pz7WjvxSs0sBACBkEXZa0ekp0ZKk7fklJlcCAEDoIuy0oszUWEnS1lzCDgAAZiHstKLuzhhJ0rY8hrEAADALYacVda/v2WEYCwAA8xB2WpFnGGvPoXJVVLtMrgYAgNBE2GlFyTHhahcVJsOQvj/AUBYAAGYg7LQii8Xi7d3ZlsdQFgAAZiDstLLuqUxSBgDATISdVuadpEzPDgAApiDstLJMZ/0wFiuyAAAwBWGnlXmGsXIOVai8utbkagAACD2EnVaWFONQUnS4JLFHFgAAJiDstIFMJikDAGAawk4bYJIyAADmIey0Ae61AwCAeQg7bYANQQEAMA9hpw14hrH2FVaorIoVWQAAtCXCThtoFx2u5BiHJGk7K7IAAGhThJ02cnjbCObtAADQlgg7bYQVWQAAmIOw00a6e1dkMYwFAEBbIuy0Ec8wFj07AAC0LcJOG/Hca2d/UaVKKmtMrgYAgNBB2Gkj8ZFhSo1jRRYAAG2NsNOGmKQMAEDbI+y0oUxnXdjZmkvPDgAAbYWw04a8k5Tz6dkBAKCtEHbaEBuCAgDQ9gg7bSizvmcnr7hKRRWsyAIAoC0QdtpQXESY2sdHSGKSMgAAbYWw08YyuZMyAABtirDTxro72RAUAIC2RNhpY9577bAiCwCANkHYaWOeScoMYwEA0DYIO23MM2fnQEmVCsurTa4GAIDgR9hpYzEOu05LiJRE7w4AAG2BsGOCw0NZzNsBAKC1mRp2Zs+erSFDhig2NlZOp1MTJkzQ1q1bfc4ZMWKELBaLz+PXv/61zzl79uzR+PHjFRUVJafTqdtvv121tbVt+VVOChuCAgDQduxmfvjq1auVnZ2tIUOGqLa2Vr/73e80evRoffPNN4qOjvaed9111+nBBx/0vo6KivI+d7lcGj9+vNLS0vTJJ5/oxx9/1K9+9SuFhYXpkUceadPv01SZTiYpAwDQVkwNO8uWLfN5PX/+fDmdTm3cuFHnnXeetz0qKkppaWnHfI/33ntP33zzjd5//32lpqbqjDPO0EMPPaQ777xTs2bNUnh4eKt+h+Zg+TkAAG3Hr+bsFBUVSZISExN92hcsWKDk5GT17dtXd999t8rLy73H1q5dq379+ik1NdXbNmbMGBUXF2vLli3H/JyqqioVFxf7PNpSt/qenYLSah0qY0UWAACtydSenSO53W7NmDFDw4cPV9++fb3tv/zlL9WpUyelp6frq6++0p133qmtW7fqjTfekCTl5ub6BB1J3te5ubnH/KzZs2frgQceaKVvcmLRDrs6tIvU3p8qtC2vRGednmRaLQAABDu/CTvZ2dn6+uuv9fHHH/u0X3/99d7n/fr1U/v27TVy5Eh9//336tq1a7M+6+6779bMmTO9r4uLi5WRkdG8wpupe2qs9v5Uoe2EHQAAWpVfDGNNnz5dS5cu1QcffKAOHToc99xhw4ZJknbs2CFJSktLU15ens85nteNzfNxOByKi4vzebS17mwICgBAmzA17BiGoenTp2vx4sVauXKlunTpcsJrNm3aJElq3769JCkrK0ubN29Wfn6+95zly5crLi5OvXv3bpW6W0J37rUDAECbMHUYKzs7WwsXLtSbb76p2NhY7xyb+Ph4RUZG6vvvv9fChQt14YUXKikpSV999ZVuueUWnXfeeerfv78kafTo0erdu7euuuoqPfbYY8rNzdXvf/97ZWdny+FwmPn1juvwiix6dgAAaE2m9uzMnTtXRUVFGjFihNq3b+99vPrqq5Kk8PBwvf/++xo9erR69uypW2+9VRMnTtTbb7/tfQ+bzaalS5fKZrMpKytLV155pX71q1/53JfHH3VNiZHFIh0qq1ZBaZXZ5QAAELRM7dkxDOO4xzMyMrR69eoTvk+nTp303//+t6XKahOR4TZ1TIzS7oPl2pZXouQY/+2FAgAgkPnFBOVQlen0bBvBUBYAAK2FsGMizyTlrUxSBgCg1RB2TMSGoAAAtD7CjokyUw9vCHqi+UsAAKB5CDsm6poSI6tFKqqo0YESVmQBANAaCDsmigizqVNStCTupAwAQGsh7Jgs08mdlAEAaE2EHZMdvpMyYQcAgNZA2DHZkZOUAQBAyyPsmOzw7uclrMgCAKAVEHZMdnpKtGxWi0oqa5VXzIosAABaGmHHZA67TZ2SoiQxSRkAgNZA2PED3Z2Hh7IAAEDLIuz4Ac8eWWwICgBAyyPs+IFMzyRllp8DANDiCDt+wLMiawd7ZAEA0OIIO36gS3K07FaLSqpq9WNRpdnlAAAQVAg7fiDcblXnZM8eWQxlAQDQkgg7foJJygAAtA7Cjp848k7KAACg5RB2/IQ37OTTswMAQEsi7PgJzzDWDvbIAgCgRRF2/ESnpGiF2Swqq3ZpX2GF2eUAABA0CDt+Isxm1enJTFIGAKClEXb8SGb9UNZWJikDANBiCDt+hBVZAAC0PMKOH+FeOwAAtDzCjh/xbAi6I79UbjcrsgAAaAmEHT/SKTFK4TarKmpc2vsTK7IAAGgJhB0/YrdZdXoKe2QBANCSCDt+5vCdlAk7AAC0BMKOn2GSMgAALYuw42cyWX4OAECLIuz4me5HrMhysSILAIBTRtjxMx0To+SwW1VV61bOoXKzywEAIOARdvyMzWpR15S6eTsMZQEAcOoIO37IO0k5n0nKAACcKsKOH2KSMgAALYew44cObwhKzw4AAKeKsOOHPMNY3x9gRRYAAKeKsOOHMtpFKSLMqupat3YfLDO7HAAAAhphxw9ZrRZ1c3pWZDGUBQDAqSDs+Knuzrp5O9uZpAwAwCkh7Pip7mmeDUHp2QEA4FQQdvzU4Q1B6dkBAOBUEHb8VGb9MNYPB8pU63KbXA0AAIGLsOOnTkuIVFS4TdUut3YdZI8sAACai7Djp6xWizKdDGUBAHCqCDt+zLNtxFbCDgAAzUbY8WOHJymzIgsAgOYi7PgxNgQFAODUEXb8mGdD0J0FZaquZUUWAADNQdjxY+nxEYpx2FXrNrSLPbIAAGgWwo4fs1iO3COLoSwAAJqDsOPnPJOU2RAUAIDmIez4Oc+8He61AwBA8xB2/BwrsgAAODWEHT/nGcbadbBcVbUuk6sBACDwmBp2Zs+erSFDhig2NlZOp1MTJkzQ1q1bfc6prKxUdna2kpKSFBMTo4kTJyovL8/nnD179mj8+PGKioqS0+nU7bffrtra2rb8Kq0mLS5CsQ67XG5DOwtYkQUAwMkyNeysXr1a2dnZ+vTTT7V8+XLV1NRo9OjRKis7/Ev9lltu0dtvv61FixZp9erV2r9/vy699FLvcZfLpfHjx6u6ulqffPKJXnjhBc2fP1/33XefGV+pxVksFmUySRkAgGazGIZhmF2Ex4EDB+R0OrV69Wqdd955KioqUkpKihYuXKjLLrtMkvTdd9+pV69eWrt2rc466yy98847uuiii7R//36lpqZKkubNm6c777xTBw4cUHh4+Ak/t7i4WPHx8SoqKlJcXFyrfsfmuOvfX+mV9Tm6+X+66dbRPcwuBwAAv9DU399+NWenqKhIkpSYmChJ2rhxo2pqajRq1CjvOT179lTHjh21du1aSdLatWvVr18/b9CRpDFjxqi4uFhbtmxpw+pbD5OUAQBoPrvZBXi43W7NmDFDw4cPV9++fSVJubm5Cg8PV0JCgs+5qampys3N9Z5zZNDxHPccO5aqqipVVVV5XxcXF7fU12gVbAgKAEDz+U3PTnZ2tr7++mu98sorrf5Zs2fPVnx8vPeRkZHR6p95Kjz32tl1sEyVNazIAgDgZPhF2Jk+fbqWLl2qDz74QB06dPC2p6Wlqbq6WoWFhT7n5+XlKS0tzXvO0auzPK895xzt7rvvVlFRkfeRk5PTgt+m5TljHYqLsMttSD8cYEUWAAAnw9SwYxiGpk+frsWLF2vlypXq0qWLz/FBgwYpLCxMK1as8LZt3bpVe/bsUVZWliQpKytLmzdvVn5+vvec5cuXKy4uTr179z7m5zocDsXFxfk8/JnFYjl8J+V85u0AAHAyTJ2zk52drYULF+rNN99UbGysd45NfHy8IiMjFR8fr2uvvVYzZ85UYmKi4uLidPPNNysrK0tnnXWWJGn06NHq3bu3rrrqKj322GPKzc3V73//e2VnZ8vhcJj59VpUZmqsNuz+iUnKAACcJFPDzty5cyVJI0aM8Gl//vnnNW3aNEnSX/7yF1mtVk2cOFFVVVUaM2aMnn76ae+5NptNS5cu1Y033qisrCxFR0dr6tSpevDBB9vqa7SJHtxrBwCAZvGr++yYxd/vsyNJn+wo0C//8Zk6J0Vp1e0/M7scAABMF5D32UHjPPfa2X2onBVZAACcBMJOgEiOCVe7qDAZhrQjn6EsAACairATIOr2yGJFFgAAJ4uwE0A8d1LemkvPDgAATUXYCSDee+2w/BwAgCYj7ASQTGf9hqAMYwEA0GSEnQDiGcbKOVSh8upak6sBACAwEHYCSFKMQ0nR4ZJYkQUAQFMRdgJMJndSBgDgpBB2AgyTlAEAODmEnQDjudcOG4ICANA0hJ0A093JMBYAACeDsBNgPMNY+worVFbFiiwAAE6EsBNg2kWHKznGIUnazoosAABOiLATgLp7V2QxbwcAgBMh7AQgVmQBANB0hJ0AxL12AABoOsJOAKJnBwCApiPsBKDu9RuC7i+qVElljcnVAADg3wg7ASg+KkzOWFZkAQDQFISdAMVQFgAATUPYCVBMUgYAoGkIOwGqB3tkAQDQJISdAJXpHcaiZwcAgOMh7AQozzBWbnGliipYkQUAQGMIOwEqLiJM7eMjJEk78hnKAgCgMYSdAJbpnbfDUBYAAI0h7ASw7s66oaytufTsAADQGMJOAPPea4dhLAAAGkXYCWDcawcAgBMj7AQwz5ydAyVVKiyvNrkaAAD8E2EngMU47DotIVISvTsAADSGsBPgDg9lMW8HAIBjIewEODYEBQDg+Ag7AS7TySRlAACOh7AT4Fh+DgDA8RF2Aly3+p6dgtJqHSpjRRYAAEcj7AS4aIddHdp5VmTRuwMAwNEIO0GAScoAADSuWWEnJydHe/fu9b5et26dZsyYoWeffbbFCkPTcSdlAAAa16yw88tf/lIffPCBJCk3N1cXXHCB1q1bp3vuuUcPPvhgixaIE+vu9Ox+Ts8OAABHa1bY+frrrzV06FBJ0muvvaa+ffvqk08+0YIFCzR//vyWrA9NcHhFFj07AAAcrVlhp6amRg6HQ5L0/vvv6+c//7kkqWfPnvrxxx9brjo0STdnjCwW6VBZtQpKq8wuBwAAv9KssNOnTx/NmzdPH330kZYvX66xY8dKkvbv36+kpKQWLRAnFhluU0a7KEkMZQEAcLRmhZ1HH31UzzzzjEaMGKErrrhCAwYMkCS99dZb3uEttK3u9ZOUtzNJGQAAH/bmXDRixAgVFBSouLhY7dq187Zff/31ioqKarHi0HSZqbF6/9t8enYAADhKs3p2KioqVFVV5Q06u3fv1pNPPqmtW7fK6XS2aIFomh7ee+3QswMAwJGaFXZ+8Ytf6MUXX5QkFRYWatiwYXr88cc1YcIEzZ07t0ULRNN477WTXyLDMEyuBgAA/9GssPP555/r3HPPlSS9/vrrSk1N1e7du/Xiiy/qqaeeatEC0TRdU2JktUiF5TU6wIosAAC8mhV2ysvLFRtbN2zy3nvv6dJLL5XVatVZZ52l3bt3t2iBaJqIMJs6JUVLYigLAIAjNSvsdOvWTUuWLFFOTo7effddjR49WpKUn5+vuLi4Fi0QTZfp9GwbwSRlAAA8mhV27rvvPt12223q3Lmzhg4dqqysLEl1vTwDBw5s0QLRdJ47KRN2AAA4rFlLzy+77DKdc845+vHHH7332JGkkSNH6pJLLmmx4nBy2BAUAICGmhV2JCktLU1paWne3c87dOjADQVNdmTPjmEYslgsJlcEAID5mjWM5Xa79eCDDyo+Pl6dOnVSp06dlJCQoIceekhut7ula0QTnZ4SLZvVopLKWuUVsyILAACpmT0799xzj/75z3/qj3/8o4YPHy5J+vjjjzVr1ixVVlbq4YcfbtEi0TQOu02dkqL0w4EybcsrUVp8hNklAQBgumaFnRdeeEH/+Mc/vLudS1L//v112mmn6aabbiLsmKi7M9Ybds7rnmJ2OQAAmK5Zw1iHDh1Sz549G7T37NlThw4dOuWi0HxsCAoAgK9mhZ0BAwZozpw5DdrnzJmj/v37n3JRaL5MzyTlfJafAwAgNTPsPPbYY3ruuefUu3dvXXvttbr22mvVu3dvzZ8/X3/+85+b/D4ffvihLr74YqWnp8tisWjJkiU+x6dNmyaLxeLzGDt2rM85hw4d0pQpUxQXF6eEhARde+21Ki0N3V4Nz4qsHXml7JEFAICaGXbOP/98bdu2TZdccokKCwtVWFioSy+9VFu2bNFLL73U5PcpKyvTgAED9Pe//73Rc8aOHasff/zR+3j55Zd9jk+ZMkVbtmzR8uXLtXTpUn344Ye6/vrrm/O1gkKX5GjZrRaVVNXqx6JKs8sBAMB0FqMF//f/yy+/1JlnnimXy3XyhVgsWrx4sSZMmOBtmzZtmgoLCxv0+Hh8++236t27t9avX6/BgwdLkpYtW6YLL7xQe/fuVXp6epM+u7i4WPHx8SoqKgqK7S5GPbFaO/JLNf/qIRrRw2l2OQAAtIqm/v5uVs9OW1q1apWcTqd69OihG2+8UQcPHvQeW7t2rRISErxBR5JGjRolq9Wqzz77rNH3rKqqUnFxsc8jmDBJGQCAw/w67IwdO1YvvviiVqxYoUcffVSrV6/WuHHjvD1Hubm5cjp9ey7sdrsSExOVm5vb6PvOnj1b8fHx3kdGRkarfo+2lulkjywAADyavV1EW5g8ebL3eb9+/dS/f3917dpVq1at0siRI5v9vnfffbdmzpzpfV1cXBxUgce7bUQ+PTsAAJxU2Ln00kuPe7ywsPBUajmh008/XcnJydqxY4dGjhyptLQ05efn+5xTW1urQ4cOKS0trdH3cTgccjgcrVqrmTzDWDvYIwsAgJMLO/Hx8Sc8/qtf/eqUCjqevXv36uDBg2rfvr0kKSsrS4WFhdq4caMGDRokSVq5cqXcbreGDRvWanX4u87J0QqzWVRW7dK+wgp1aBdldkkAAJjmpMLO888/36IfXlpaqh07dnhf79y5U5s2bVJiYqISExP1wAMPaOLEiUpLS9P333+vO+64Q926ddOYMWMkSb169dLYsWN13XXXad68eaqpqdH06dM1efLkJq/ECkZhNqu6JEdrW16ptueVEnYAACHN1AnKGzZs0MCBAzVw4EBJ0syZMzVw4EDdd999stls+uqrr/Tzn/9c3bt317XXXqtBgwbpo48+8hmCWrBggXr27KmRI0fqwgsv1DnnnKNnn33WrK/kN7x3UmaSMgAgxJk6QXnEiBHHvcvvu+++e8L3SExM1MKFC1uyrKDQ3Rmr/+hHbWP5OQAgxPn10nM0X4+0+nvtsEcWACDEEXaClGcYa3teqdxu9sgCAIQuwk6Q6pQYpXCbVRU1dSuyAAAIVYSdIGW3WXV6SrQkJikDAEIbYSeIee+kzCRlAEAII+wEMc+dlOnZAQCEMsJOEONeOwAAEHaCmmcYa0d+qVysyAIAhCjCThDrmBglh92qqlq3cg6Vm10OAACmIOwEMZvVoq4pzNsBAIQ2wk6Q80xS3p7PiiwAQGgi7AQ5JikDAEIdYSfIca8dAECoI+wEOc8w1vcHWJEFAAhNhJ0gl9EuShFhVlXXurX7YJnZ5QAA0OYIO0HOarWom9OzIouhLABA6CHshIDuzrp5O9uZpAwACEGEnRDgXZHF8nMAQAgi7IQA77126NkBAIQgwk4I8Cw//+FAmWpdbpOrAQCgbRF2QsBpCZGKDLOp2uXWroPskQUACC2EnRBgtVqUyVAWACBEEXZCRKaTOykDAEITYSdE9Eirv9dOPj07AIDQQtgJEZ7l5wxjAQBCDWEnRHhWZO0sKFMNK7IAACGEsBMi0uMjFOOwq8ZlaFcBe2QBAEIHYSdEWCzskQUACE2EnRDiuZPyVubtAABCCGEnhHRnkjIAIAQRdkKId0NQwg4AIIQQdkKIZxhr18FyVdW6TK4GAIC2QdgJIWlxEYp12OVyG9rJiiwAQIgg7IQQi+XwHlmsyAIAhArCTohhkjIAINQQdkIMk5QBAKGGsBNiPJOUtzOMBQAIEYSdEOMZxtp1sEyVNazIAgAEP8JOiHHGOhQXYZfbkH44wIosAEDwI+yEGIvFcniScj7zdgAAwY+wE4KYpAwACCWEnRDUnXvtAABCCGEnBHGvHQBAKCHshCDPXZR3HypnRRYAIOgRdkJQSoxDCVFhMgxpRz5DWQCA4EbYCUEWi0XdnazIAgCEBsJOiGJDUABAqCDshKgeaUxSBgCEBsJOiMp0eu61Q88OACC4EXZClOdeOzk/lauimhVZAIDgRdgJUUkxDiVFh7MiCwAQ9Ag7IezwJGXm7QAAghdhJ4R1Z48sAEAIIOyEMDYEBQCEAsJOCOvu5F47AIDgR9gJYZ5hrH2FFSqrqjW5GgAAWgdhJ4S1iw5XcoxDkrSdFVkAgCBF2Alx3VmRBQAIcoSdEOcZymLbCABAsDI17Hz44Ye6+OKLlZ6eLovFoiVLlvgcNwxD9913n9q3b6/IyEiNGjVK27dv9znn0KFDmjJliuLi4pSQkKBrr71WpaUMyTQVG4ICAIKdqWGnrKxMAwYM0N///vdjHn/sscf01FNPad68efrss88UHR2tMWPGqLKy0nvOlClTtGXLFi1fvlxLly7Vhx9+qOuvv76tvkLAo2cHABDsLIZhGGYXIUkWi0WLFy/WhAkTJNX16qSnp+vWW2/VbbfdJkkqKipSamqq5s+fr8mTJ+vbb79V7969tX79eg0ePFiStGzZMl144YXau3ev0tPTm/TZxcXFio+PV1FRkeLi4lrl+/mrovIaDXjwPUnS5lmjFRsRZnJFAAA0TVN/f/vtnJ2dO3cqNzdXo0aN8rbFx8dr2LBhWrt2rSRp7dq1SkhI8AYdSRo1apSsVqs+++yzRt+7qqpKxcXFPo9QFR8VJmcsK7IAAMHLb8NObm6uJCk1NdWnPTU11XssNzdXTqfT57jdbldiYqL3nGOZPXu24uPjvY+MjIwWrj6wMJQFAAhmfht2WtPdd9+toqIi7yMnJ8fskkzFJGUAQDDz27CTlpYmScrLy/Npz8vL8x5LS0tTfn6+z/Ha2lodOnTIe86xOBwOxcXF+TxCGRuCAgCCmd+GnS5duigtLU0rVqzwthUXF+uzzz5TVlaWJCkrK0uFhYXauHGj95yVK1fK7XZr2LBhbV5zoPLcWHA7PTsAgCBkN/PDS0tLtWPHDu/rnTt3atOmTUpMTFTHjh01Y8YM/eEPf1BmZqa6dOmie++9V+np6d4VW7169dLYsWN13XXXad68eaqpqdH06dM1efLkJq/EgtTNWdezk1tcqaKKGsVHsiILABA8TA07GzZs0M9+9jPv65kzZ0qSpk6dqvnz5+uOO+5QWVmZrr/+ehUWFuqcc87RsmXLFBER4b1mwYIFmj59ukaOHCmr1aqJEyfqqaeeavPvEsjiI8OUFheh3OJK7cgv0aBOiWaXBABAi/Gb++yYKZTvs+Nx1T8/00fbCzT70n66YmhHs8sBAOCEAv4+O2hbTFIGAAQrwg4kST2899phkjIAILgQdiDpyHvt0LMDAAguhB1IkjLre3byS6pUVF5jcjUAALQcwg4kSTEOu05LiJQkbcundwcAEDwIO/BiKAsAEIwIO/DyrsjKJewAAIIHYQdemU42BAUABB/CDrw8PTvbmbMDAAgihB14davv2SkordahsmqTqwEAoGUQduAV7bCrQ7v6FVlMUgYABAnCDnx4h7IIOwCAIEHYgY/Dy8+ZpAwACA6EHfjo7mRDUABAcCHswMfhFVn07AAAggNhBz66OWNksUiHyqpVUFpldjkAAJwywg58RIbblNEuShJDWQCA4EDYQQPd6ycpb2eSMgAgCBB20EBmKpOUAQDBg7CDBujZAQAEE8IOGsj0LD/PL5FhGCZXAwDAqSHsoIFuzhhZLVJheY0OsCILABDgCDtoICLMpo6JdSuyGMoCAAQ6wg6OiUnKAIBgQdjBMXVnjywAQJAg7OCY2P0cABAsCDs4pu5HDGOxIgsAEMgIOzim01OiZbNaVFxZq/wSVmQBAAIXYQfH5LDb1CmJPbIAAIGPsINGdffcXJBJygCAAEbYQaO8K7Jy6dkBAAQuwg4a5b3XTj5hBwAQuAg7aJRnRdaOvFJWZAEAAhZhB43qkhwtu9Wikqpa/VhUaXY5AAA0C2EHjQq3W9U5OVoSK7IAAIGLsIPj8kxSZkNQAECgIuzguDKdbAgKAAhshB0cl3fbiHx6dgAAgYmwg+PyDGPtYI8sAECAIuzguDonRyvMZlFZtUv7CivMLgcAgJNG2MFxhdms6lK/ImvGK5v05qZ9qqxxmVwVAABNZze7APi/ywZ10Ox3vtOG3T9pw+6flBAVpksGnqYrhnb0zukBAMBfWQwmYqi4uFjx8fEqKipSXFyc2eX4pX2FFXptfY4WbcjR/iNuMHhmxwRNHtpRF/Vvr6hwsjMAoO009fc3YUeEnZPhchv6cNsBvbxuj1Z8ly+Xu+4fn1iHXT8/I11XDO2ovqfFm1wlACAUEHZOAmGnefKLK7Vo4169uj5Hew6Ve9v7nhanyUM66hdnpCs2IszECgEAwYywcxIIO6fG7Ta09oeDenndHr23JU/VLrckKTLMpov6t9fkoR11ZscEWSwWkysFAAQTws5JIOy0nENl1Xrj8716ed0efX+gzNvePTVGk4d01KVnnqaEqHATKwQABAvCzkkg7LQ8wzC0cfdPenldjv6zeb8qa+p6e8LtVo3rm6bJQzrqrNMT6e0BADQbYeckEHZaV1FFjd7atE8vr8vRNz8We9s7J0Vp0pCOumxQB6XEOkysEAAQiAg7J4Gw0zYMw9DmfUV6eV2O3tq0T2XVdTcntFstGtUrVZOHZujczBTZrPT2AABOjLBzEgg7ba+sqlZLv9qvl9flaFNOobf9tIRIXT44Q5cP6aD28ZHmFQgA8HuEnZNA2DHXd7nFemVdjt74fK+KK2slSVaLNKKHU5OHZOh/ejplt7GzCQDAF2HnJBB2/ENljUvvfP2jXl6Xo3U7D3nbnbEO/e/gDpo0uKM6JkWZWCEAwJ8Qdk4CYcf/fH+gVK+uz9G/N+7VwbJqb/s53ZI1eWiGLuidKofdZmKFAACzEXZOAmHHf1XXuvX+t3l6ed0efbyjQJ5/WhOjwzXxzNM0aUhHdXPGmFskAMAUhJ2TQNgJDDmHyvXahhy9tiFHecVV3vahnRM1eWiGLuzXXhFh9PYAQKgg7JwEwk5gqXW5tWrrAb2yfo9Wfpev+r1IFRdh1yUDT9PkoR3Vqz0/RwAIdoSdk0DYCVy5RZVatCFHr6zP0b7CCm/7gIwEXTEkQxcPSFe0w25ihQCA1tLU399+vZ531qxZslgsPo+ePXt6j1dWVio7O1tJSUmKiYnRxIkTlZeXZ2LFaGtp8RG6eWSmPrrjZ3rxmqG6sF+a7FaLvswp1F1vbNbQh9/XXf/+SptyCkWuB4DQ5Pf/y9unTx+9//773td2++GSb7nlFv3nP//RokWLFB8fr+nTp+vSSy/VmjVrzCgVJrJaLTqve4rO656igtIq/XvjXr26Pkc/FJTplfV1PT8902J1+eAM9esQr85J0UqOCWdvLgAIAX49jDVr1iwtWbJEmzZtanCsqKhIKSkpWrhwoS677DJJ0nfffadevXpp7dq1Ouuss5r8OQxjBSfDMPTZzkN6Zd0e/ffrXFXXun2Oxzrs6pwcrc7J0eqSFOV9fnpyNDuzA0AAaOrvb7/v2dm+fbvS09MVERGhrKwszZ49Wx07dtTGjRtVU1OjUaNGec/t2bOnOnbseNJhB8HJYrHorNOTdNbpSZpVXq3FX+zTyu/ytbOgTPsKK1RSVavN+4q0eV9Rg2sTosLUOSlaXZLrHnWBKFqdk6MUGxFmwrcBADSXX4edYcOGaf78+erRo4d+/PFHPfDAAzr33HP19ddfKzc3V+Hh4UpISPC5JjU1Vbm5ucd936qqKlVVHV66XFxcfJyzEQwSosJ19fAuunp4F0l1d2vOOVSunQVl2nWwTDsLyrWzoFS7CsqVW1ypwvIabSov9Nm3yyM5JrwuACXVhyDv8yhFhfv1v1IAEJL8+r/M48aN8z7v37+/hg0bpk6dOum1115TZGTzN4mcPXu2HnjggZYoEQEqIsymzNRYZabGNjhWXl2r3QfLtaugTD8UlGnXEYGooLRKBaXVKiit1vpdPzW4Ni0uQp2To3zC0OnJ0cpIjOIeQABgEr8OO0dLSEhQ9+7dtWPHDl1wwQWqrq5WYWGhT+9OXl6e0tLSjvs+d999t2bOnOl9XVxcrIyMjNYqGwEmKtyuXu3jjnmvnpLKGu0qKNfOg/UhqKBMOw+WaWdBmQrLa5RbXKnc4kp9+sMhn+ssFik9PtJ3WCw5Sp2T6oJQGBudAkCrCaiwU1paqu+//15XXXWVBg0apLCwMK1YsUITJ06UJG3dulV79uxRVlbWcd/H4XDI4XC0RckIMrERYerXIV79OsQ3OFZYXn3UsNjhQFRSVat9hRXaV1ihj3cU+Fxns1qU0S6yboJ00uEwdHpytNITImWzsmIMAE6FX6/Guu2223TxxRerU6dO2r9/v+6//35t2rRJ33zzjVJSUnTjjTfqv//9r+bPn6+4uDjdfPPNkqRPPvnkpD6H1VhoTYZh6GBZ9TGHxXYVlKmixtXoteE2qzISI73DYl1S6iZKd0qOVlJ0OENjAEJaUKzG2rt3r6644godPHhQKSkpOuecc/Tpp58qJSVFkvSXv/xFVqtVEydOVFVVlcaMGaOnn37a5KoBXxaLRckxDiXHODS4c6LPMcMwlF9SpR8O1AWgXQVl3t6hXQfLVV3r1vcHyvT9gbJjvne43ar4yDAlRIbV/RkVpjjP88hwxUfalRAVrvjIMMVH1bV7HgydAQgVft2z01bo2YE/crsN7S+q8Jkj5Bkay/mpXDWuU/tXNzrcpoSo8PpwZK8PR0cFpqgjg1Pd89gIu6wMrQHwA0HRswOEMqvVog7totShXZTOyUz2OWYYhsqqXSosr1ZRRU3do7zuz8L614XlNSr2PK+o9raVVNZKksqqXSqrrvDZU6wpLBYpLuJwEDry4dsW3qAtKtzGXasBtDnCDhCALBaLYhx2xTjs6tDu5K51uQ1vCDoyHBWVHw5ERx4rPqKtosYlw5D3+MkKs1kaBKQoh12RYba6R7hNEZ7nYVbf1+F1f0Yc8dzT7rBbCVEAGkXYAUKMzWpRu+hwtYs++S0xqmpdKjoqABWW+wajurbqBm01LkM1LsN7n6KW5huIrL7h6DhhKcInOFkbnH/kOcxzAgITYQdAkznsNjljbXLGRpzUdYZhqLzadVTPUV0gqqh2qaLGrYoalyprXPWv6x6VRzyvqK4/7n3uVrXr8H5nnvNak91qaRCQ6p5bFeOwK7q+ty0mwq7YI17HRtgV4whTtMPmfR4TYVdUmI35T0AbIOwAaHUWi0XR9b/80xOaf/fzo9W63KqsdTcIQicOS42EqyNeH/ncXT8XvNZtqKSqViVVtS32HTzDkdEOm2IiwhTrfe0JSXXhKdph9x6L8bQf8ZyhPKBxhB0AActusyrGVter0loMw1C1y63K+oBUcYxAVF7jUnlVrUqralVSWasyz/OqWpUe+bqy7s/Sqlq56hOU5/WpslstviHo6FDUSEg6+rnDbpPVKtmtVlktIkAhKBB2AOA4LBaLHHabHHab4tUyO94bhqGqWrdvMKoPQmVHhKTSqhqVVbnqj9U/r6pVaWVN/bkub1CqdRsqLK8bJmxJNqtFNqtFdqtFNotFNlv9n/VtVs8x78Mqm1WyWa2Hr7FaZLdZZLUcfa7F9/29z61159rq2yzHO/fIGnw/2261KMxmld1W955hNovsNqtPe5i1/vgRz8Pqz7FZLYS9IEHYAYA2ZrFYFFE/WTol9tS2rnG7DZVVHxGUKhs+L62sVWm1J0Ad8WeV77lVte4G7+9yG3K5DbX8lPLAEFYflI4MQYcD1DHCVKPnesKWb/AKs9YHMJ/gdbg9zGaRw25VmK3uEV7/PNz73OJtD7dZFVbfFm5jWPNIhB0ACGBWq0WxEWGKjTj1XqfqWrdq3W7Vug25XIZchuENOy63Udfufe6W2y3Vut0+57gMo8H1tW5D7qP+dNVfV3vEdS5X/TnG0ece+fluudyq+9Oo+7PWdfgal9tQravuz5r6YzWuuu9U63KrxlVXu2973bnHusVu3SpCl9SyHWZt4sgg1FhAOmb7EccOBynfa8LsVjlsVoXZD18TZj/6WovP65RYh2krGgk7AABJdduPhCt0l9e73CcORjWuute17vrjrsOhqtblVk39tUe2N/6envfxvNfR13uucau61q3q+vfyvD7cXne9Zx6YhyeolVe37irFpnp/5nnq5ow15bMJOwAAyDM/KXA31/WEtWqXWzWeEFRbN8HeE46ODkje0HRUiKpx1c0rqznyvVxuVde/X80R1/m8R63RoN3zOeE28/5uCTsAAAQBT1iLCAvcwNZaQre/EgAAhATCDgAACGqEHQAAENQIOwAAIKgRdgAAQFAj7AAAgKBG2AEAAEGNsAMAAIIaYQcAAAQ1wg4AAAhqhB0AABDUCDsAACCoEXYAAEBQI+wAAICgZje7AH9gGIYkqbi42ORKAABAU3l+b3t+jzeGsCOppKREkpSRkWFyJQAA4GSVlJQoPj6+0eMW40RxKAS43W7t379fsbGxslgsLfa+xcXFysjIUE5OjuLi4lrsfdE8/Dz8Dz8T/8LPw7/w8zgxwzBUUlKi9PR0Wa2Nz8yhZ0eS1WpVhw4dWu394+Li+AfVj/Dz8D/8TPwLPw//ws/j+I7Xo+PBBGUAABDUCDsAACCoEXZakcPh0P333y+Hw2F2KRA/D3/Ez8S/8PPwL/w8Wg4TlAEAQFCjZwcAAAQ1wg4AAAhqhB0AABDUCDsAACCoEXZa0d///nd17txZERERGjZsmNatW2d2SSFp9uzZGjJkiGJjY+V0OjVhwgRt3brV7LJQ749//KMsFotmzJhhdikha9++fbryyiuVlJSkyMhI9evXTxs2bDC7rJDlcrl07733qkuXLoqMjFTXrl310EMPnXD/JzSOsNNKXn31Vc2cOVP333+/Pv/8cw0YMEBjxoxRfn6+2aWFnNWrVys7O1uffvqpli9frpqaGo0ePVplZWVmlxby1q9fr2eeeUb9+/c3u5SQ9dNPP2n48OEKCwvTO++8o2+++UaPP/642rVrZ3ZpIevRRx/V3LlzNWfOHH377bd69NFH9dhjj+lvf/ub2aUFLJaet5Jhw4ZpyJAhmjNnjqS6/bcyMjJ0880366677jK5utB24MABOZ1OrV69Wuedd57Z5YSs0tJSnXnmmXr66af1hz/8QWeccYaefPJJs8sKOXfddZfWrFmjjz76yOxSUO+iiy5Samqq/vnPf3rbJk6cqMjISP3rX/8ysbLARc9OK6iurtbGjRs1atQob5vVatWoUaO0du1aEyuDJBUVFUmSEhMTTa4ktGVnZ2v8+PE+/56g7b311lsaPHiw/vd//1dOp1MDBw7U//3f/5ldVkg7++yztWLFCm3btk2S9OWXX+rjjz/WuHHjTK4scLERaCsoKCiQy+VSamqqT3tqaqq+++47k6qCVNfDNmPGDA0fPlx9+/Y1u5yQ9corr+jzzz/X+vXrzS4l5P3www+aO3euZs6cqd/97ndav369fvOb3yg8PFxTp041u7yQdNddd6m4uFg9e/aUzWaTy+XSww8/rClTpphdWsAi7CCkZGdn6+uvv9bHH39sdikhKycnR7/97W+1fPlyRUREmF1OyHO73Ro8eLAeeeQRSdLAgQP19ddfa968eYQdk7z22mtasGCBFi5cqD59+mjTpk2aMWOG0tPT+Zk0E2GnFSQnJ8tmsykvL8+nPS8vT2lpaSZVhenTp2vp0qX68MMP1aFDB7PLCVkbN25Ufn6+zjzzTG+by+XShx9+qDlz5qiqqko2m83ECkNL+/bt1bt3b5+2Xr166d///rdJFeH222/XXXfdpcmTJ0uS+vXrp927d2v27NmEnWZizk4rCA8P16BBg7RixQpvm9vt1ooVK5SVlWViZaHJMAxNnz5dixcv1sqVK9WlSxezSwppI0eO1ObNm7Vp0ybvY/DgwZoyZYo2bdpE0Gljw4cPb3Arhm3btqlTp04mVYTy8nJZrb6/nm02m9xut0kVBT56dlrJzJkzNXXqVA0ePFhDhw7Vk08+qbKyMl199dVmlxZysrOztXDhQr355puKjY1Vbm6uJCk+Pl6RkZEmVxd6YmNjG8yXio6OVlJSEvOoTHDLLbfo7LPP1iOPPKLLL79c69at07PPPqtnn33W7NJC1sUXX6yHH35YHTt2VJ8+ffTFF1/oiSee0DXXXGN2aQGLpeetaM6cOfrTn/6k3NxcnXHGGXrqqac0bNgws8sKORaL5Zjtzz//vKZNm9a2xeCYRowYwdJzEy1dulR33323tm/fri5dumjmzJm67rrrzC4rZJWUlOjee+/V4sWLlZ+fr/T0dF1xxRW67777FB4ebnZ5AYmwAwAAghpzdgAAQFAj7AAAgKBG2AEAAEGNsAMAAIIaYQcAAAQ1wg4AAAhqhB0AABDUCDsAcAwWi0VLliwxuwwALYCwA8DvTJs2TRaLpcFj7NixZpcGIACxNxYAvzR27Fg9//zzPm0Oh8OkagAEMnp2APglh8OhtLQ0n0e7du0k1Q0xzZ07V+PGjVNkZKROP/10vf766z7Xb968Wf/zP/+jyMhIJSUl6frrr1dpaanPOc8995z69Okjh8Oh9u3ba/r06T7HCwoKdMkllygqKkqZmZl66623WvdLA2gVhB0AAenee+/VxIkT9eWXX2rKlCmaPHmyvv32W0lSWVmZxowZo3bt2mn9+vVatGiR3n//fZ8wM3fuXGVnZ+v666/X5s2b9dZbb6lbt24+n/HAAw/o8ssv11dffaULL7xQU6ZM0aFDh9r0ewJoAQYA+JmpU6caNpvNiI6O9nk8/PDDhmEYhiTj17/+tc81w4YNM2688UbDMAzj2WefNdq1a2eUlpZ6j//nP/8xrFarkZubaxiGYaSnpxv33HNPozVIMn7/+997X5eWlhqSjHfeeafFvieAtsGcHQB+6Wc/+5nmzp3r05aYmOh9npWV5XMsKytLmzZtkiR9++23GjBggKKjo73Hhw8fLrfbra1bt8pisWj//v0aOXLkcWvo37+/93l0dLTi4uKUn5/f3K8EwCSEHQB+KTo6usGwUkuJjIxs0nlhYWE+ry0Wi9xud2uUBKAVMWcHQED69NNPG7zu1auXJKlXr1768ssvVVZW5j2+Zs0aWa1W9ejRQ7GxsercubNWrFjRpjUDMAc9OwD8UlVVlXJzc33a7Ha7kpOTJUmLFi3S4MGDdc4552jBggVat26d/vnPf0qSpkyZovvvv19Tp07VrFmzdODAAd1888266qqrlJqaKkmaNWuWfv3rX8vpdGrcuHEqKSnRmjVrdPPNN7ftFwXQ6gg7APzSsmXL1L59e5+2Hj166LvvvpNUt1LqlVde0U033aT27dvr5ZdfVu/evSVJUVFRevfdd/Xb3/5WQ4YMUVRUlCZOnKgnnnjC+15Tp05VZWWl/vKXv+i2225TcnKyLrvssrb7ggDajMUwDMPsIgDgZFgsFi1evFgTJkwwuxQAAYA5OwAAIKgRdgAAQFBjzg6AgMPoO4CTQc8OAAAIaoQdAAAQ1Ag7AAAgqBF2AABAUCPsAACAoEbYAQAAQY2wAwAAghphBwAABDXCDgAACGr/H6KloPqHqR7jAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(LSTM(\n",
       "   (inlayernorm): LayerNorm((15,), eps=1e-05, elementwise_affine=True)\n",
       "   (clayernorm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "   (lstm): LSTM(15, 256, bias=False, batch_first=True, bidirectional=True)\n",
       "   (fc1): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (fc2): Linear(in_features=512, out_features=512, bias=True)\n",
       "   (linear_class): Linear(in_features=512, out_features=6, bias=True)\n",
       " ),\n",
       " [279.4885425083339,\n",
       "  65.67314185388386,\n",
       "  51.4968044818379,\n",
       "  46.27308345772326,\n",
       "  43.82820654427633,\n",
       "  42.42349716182798,\n",
       "  40.49429933982901,\n",
       "  39.98407355416566,\n",
       "  39.281554128043354,\n",
       "  38.394198595080525],\n",
       " [96.0638310304664,\n",
       "  98.92178497832175,\n",
       "  99.16164801389901,\n",
       "  99.24695861851357,\n",
       "  99.29058778617033,\n",
       "  99.31220759692881,\n",
       "  99.34736413604509,\n",
       "  99.34760760238247,\n",
       "  99.36094955767035,\n",
       "  99.37565492444753])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LSTM.LSTM(input_dim=15, num_classes=6, hidden_dims=256, num_layers=1, dropout=0, bidirectional=True, use_layernorm=True)\n",
    "train(model, train_dataset, batch_size, epochs, lr, weight_decay, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6b52ce4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "    print(\"Model saved successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8940a8ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully.\n"
     ]
    }
   ],
   "source": [
    "save_model(model, \"LSTM_model_10ep.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df6188af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Class distribution\n",
    "class_distribution = [28442, 469917, 236000, 32851,20606]\n",
    "\n",
    "# Calculate inverse class frequencies\n",
    "inv_class_frequencies = 1 / torch.tensor(class_distribution, dtype=torch.float)\n",
    "\n",
    "# Normalize the weights to sum up to 1\n",
    "class_weights = inv_class_frequencies / torch.sum(inv_class_frequencies)\n",
    "\n",
    "print(class_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c920560",
   "metadata": {},
   "outputs": [],
   "source": [
    "469917*0.0177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e186ef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def ensemble_learning(model_class, train_dataset, test_loader, num_models, batch_size, epochs, lr, weight_decay, device):\n",
    "#     models = []\n",
    "#     ensemble_predictions = []\n",
    "\n",
    "#     # Step 1: Create Multiple Model Instances\n",
    "#     for _ in range(num_models):\n",
    "#         model = model_class(input_dim=13, hidden_dims=128, num_classes=2, num_layers=6)\n",
    "#         models.append(model)\n",
    "\n",
    "#     # Step 2: Train Each Model\n",
    "#     for model in models:\n",
    "#         trained_model, _, _ = train(model, train_dataset, batch_size, epochs, lr, weight_decay, device)\n",
    "\n",
    "#         # Step 3: Predict with Ensemble\n",
    "#         model_predictions = []\n",
    "#         with torch.no_grad():\n",
    "#             for inputs, _ in test_loader:\n",
    "#                 inputs = inputs.to(device)\n",
    "#                 model.to(device)\n",
    "#                 model.eval()\n",
    "#                 outputs = model(inputs)\n",
    "#                 _, predicted = torch.max(outputs, 1)\n",
    "#                 model_predictions.append(predicted.cpu().numpy())\n",
    "#         ensemble_predictions.append(model_predictions)\n",
    "\n",
    "#     # Step 3 (Continued): Combine Predictions with Voting\n",
    "#     ensemble_predictions = np.stack(ensemble_predictions, axis=0)  # Shape: (num_models, num_samples, 1)\n",
    "#     ensemble_predictions = np.squeeze(ensemble_predictions, axis=2)  # Shape: (num_models, num_samples)\n",
    "#     majority_voted_predictions = np.argmax(np.bincount(ensemble_predictions, axis=0), axis=0)\n",
    "\n",
    "#     return majority_voted_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab7724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b9619",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003f53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "5//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18f340a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "icm",
   "language": "python",
   "name": "icm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
